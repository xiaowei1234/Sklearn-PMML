{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer, StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn2pmml import make_pmml_pipeline, sklearn2pmml\n",
    "from sklearn.metrics import roc_auc_score, log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run '../../code/constants.py'\n",
    "%run '../../code/feature_selection.py'\n",
    "%run '../../code/preprocessing.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(path + fin_mod_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = get_x_y(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl = Pipeline([\n",
    "    ('impute', Imputer(strategy='median'))\n",
    "    , ('standardize', StandardScaler())\n",
    "#     , ('interactions', PolynomialFeatures(include_bias=False))\n",
    "    , ('clf', SGDClassifier())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [0.0001, 0.001, 0.1]\n",
    "\n",
    "l1_ratio = [0.1, 0.2, 0.4]\n",
    "\n",
    "C_options = [0.2, 0.4, 0.6, 0.8]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid =  [\n",
    "    {\n",
    "    'clf': [SGDClassifier(penalty='elasticnet', max_iter=500, loss='log')]\n",
    "    , 'clf__l1_ratio': l1_ratio\n",
    "    , 'clf__alpha': alpha\n",
    "    }, \n",
    "    {'clf': [LogisticRegression(penalty='l2', max_iter=500)]\n",
    "    , 'clf__C': C_options\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(pl, param_grid=param_grid, scoring={'auc': auc_scorer, 'log': log_scorer}\n",
    "                    , refit='log', cv=6, verbose=5, return_train_score=True, n_jobs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 13 candidates, totalling 78 fits\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.1 \n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.1, auc=0.6140522106515179, log=-0.5227144519142847, total=   4.8s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.1, auc=0.6537962372152667, log=-0.5020934591289382, total=   4.9s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.1, auc=0.6068729363225811, log=-0.5138228553201809, total=   4.7s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.1, auc=0.6202084029114694, log=-0.5111693357826401, total=   4.7s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.1, auc=0.5983362899523078, log=-0.5172883806721958, total=   4.6s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.1, auc=0.593125907355692, log=-0.5169415011224983, total=   4.7s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.2, auc=0.6177906803863142, log=-0.5268418043784368, total=   4.8s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.2, auc=0.6542802140958847, log=-0.5013478754210231, total=   4.8s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.2, auc=0.6072536131777999, log=-0.5138531841331271, total=   4.6s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.2, auc=0.6176489085707664, log=-0.5118641888860858, total=   4.6s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.2, auc=0.601152616685245, log=-0.5168039102060457, total=   4.7s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.4 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.2, auc=0.5936981262078713, log=-0.5166862054095436, total=   4.7s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.4 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.4, auc=0.6135494941860825, log=-0.5249764113167912, total=   4.6s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.4 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.4, auc=0.6554764500721706, log=-0.5005338552438724, total=   4.6s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.4 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  14 tasks      | elapsed:   33.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.4, auc=0.6069499080056745, log=-0.5134814831040797, total=   4.4s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.4 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.4, auc=0.61750112925702, log=-0.512254205350894, total=   4.4s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.4 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.4, auc=0.5978743634181448, log=-0.5173225908165133, total=   4.5s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.0001, clf__l1_ratio=0.4, auc=0.5962515792558738, log=-0.516008958966371, total=   4.5s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.1, auc=0.6164092167782782, log=-0.5212216205864747, total=   4.5s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.1, auc=0.6551719705370362, log=-0.5016123873082252, total=   4.5s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.1, auc=0.6072054477986409, log=-0.5135104652998471, total=   4.3s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.1, auc=0.6195667866457071, log=-0.5111639488576705, total=   4.4s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.1, auc=0.6000043063573608, log=-0.516736711255595, total=   4.3s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.1, auc=0.5947468326586707, log=-0.5164071039021884, total=   4.3s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.2, auc=0.6165608370554382, log=-0.5211578772928956, total=   4.3s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.2, auc=0.6550381606090829, log=-0.5016819297050756, total=   4.3s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.2, auc=0.6070734963419092, log=-0.5135155880203252, total=   4.3s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.2, auc=0.6194732240613225, log=-0.5112100768539376, total=   4.3s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.2, auc=0.599936922708011, log=-0.516744805614139, total=   4.4s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.4 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.2, auc=0.5947274695410414, log=-0.51641964916923, total=   4.3s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.4 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.4, auc=0.6165781827868395, log=-0.5208322512338764, total=   4.4s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.4 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.4, auc=0.6547065783686339, log=-0.5019436229345999, total=   4.3s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.4 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.4, auc=0.6071521716236223, log=-0.513480600638283, total=   4.3s[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.4, auc=0.6194369763051205, log=-0.5112183730390366, total=   4.3s\n",
      "\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.4 \n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.4 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.4, auc=0.5997868198201491, log=-0.5167170507679995, total=   4.3s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.001, clf__l1_ratio=0.4, auc=0.5948018239127377, log=-0.5163710008274518, total=   4.3s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.1, auc=0.6235604591662898, log=-0.5177109138427625, total=   4.4s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.1, auc=0.6489642120391765, log=-0.5113075603856307, total=   4.5s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.1, auc=0.6065472392410003, log=-0.5156985795719135, total=   4.5s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.1, auc=0.6108589602904282, log=-0.515714985959142, total=   4.5s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.1 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.1, auc=0.5898123357620362, log=-0.5187594572542861, total=   4.4s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.1, auc=0.5849557560507419, log=-0.5192033958333843, total=   4.5s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.2, auc=0.6173389170068702, log=-0.5198219468639284, total=   4.7s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.2, auc=0.6435554412939916, log=-0.5162284948025454, total=   4.7s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.2, auc=0.6027446522490599, log=-0.5182687731148864, total=   4.6s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.2, auc=0.60001019274512, log=-0.5190265156664297, total=   4.7s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.2, auc=0.5851751014472459, log=-0.5206538577148633, total=   4.6s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.4 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.2, auc=0.5842947766673503, log=-0.5209028671611453, total=   4.7s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.4 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.4, auc=0.581817801676341, log=-0.5246350566523873, total=   4.7s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.4 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.4, auc=0.6337561097241409, log=-0.5252112901694699, total=   4.7s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.4 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.4, auc=0.5, log=-0.5264208957064773, total=   4.8s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.4 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.4, auc=0.5703451220124258, log=-0.5244705561252061, total=   4.7s\n",
      "[CV] clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.4 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.4, auc=0.5739304743251257, log=-0.5255575817479199, total=   4.7s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.2 \n",
      "[CV]  clf=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='log', max_iter=500, n_iter=None,\n",
      "       n_jobs=1, penalty='elasticnet', power_t=0.5, random_state=None,\n",
      "       shuffle=True, tol=None, verbose=0, warm_start=False), clf__alpha=0.1, clf__l1_ratio=0.4, auc=0.559313024469404, log=-0.5255368904508029, total=   4.7s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.2 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.2, auc=0.6162645657681991, log=-0.5215635501478254, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          verbose=0, warm_start=False), clf__C=0.2 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.2, auc=0.6550031594010767, log=-0.5015689995903658, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.2 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.2, auc=0.6071083426773136, log=-0.5135361989071909, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.2 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.2, auc=0.619544015619375, log=-0.5111722854309467, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.2 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.2, auc=0.6000397795888575, log=-0.5166939489711139, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.4 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.2, auc=0.5948901197291271, log=-0.5163765126974376, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.4 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.4, auc=0.6162527954504623, log=-0.5215371384164469, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.4 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.4, auc=0.6549884465039059, log=-0.5015651428638663, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.4 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.4, auc=0.6071061744608884, log=-0.5135416395962663, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.4 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.4, auc=0.6195406077106722, log=-0.5111774308115112, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.4 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.4, auc=0.6000425678777961, log=-0.516706601828199, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.6 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.4, auc=0.5948910491587732, log=-0.5163897982496604, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.6 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.6, auc=0.616249388253223, log=-0.521528341373673, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.6 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.6, auc=0.654981477236825, log=-0.5015638735660665, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          verbose=0, warm_start=False), clf__C=0.6 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.6, auc=0.6071032318814543, log=-0.5135434735271449, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.6 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  68 tasks      | elapsed:  2.1min\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.6, auc=0.6195373547069105, log=-0.5111791660819417, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.6 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.6, auc=0.600042412972855, log=-0.5167108462065821, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.8 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.6, auc=0.5948918236834784, log=-0.5163942528472103, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.8 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.8, auc=0.616247839527205, log=-0.5215239441426321, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.8 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.8, auc=0.6549834905806484, log=-0.5015632419758138, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.8 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.8, auc=0.6071009087924274, log=-0.5135443943194948, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.8 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.8, auc=0.6195373547069105, log=-0.5111800375018349, total=   0.2s\n",
      "[CV] clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.8 \n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.8, auc=0.6000436522123833, log=-0.5167129734294682, total=   0.2s\n",
      "[CV]  clf=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=500, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False), clf__C=0.8, auc=0.5948922883983015, log=-0.5163964850476063, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=2)]: Done  78 out of  78 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=6, error_score='raise',\n",
       "       estimator=Pipeline(memory=None,\n",
       "     steps=[('impute', Imputer(axis=0, copy=True, missing_values='NaN', strategy='median', verbose=0)), ('standardize', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_rat...='l2', power_t=0.5, random_state=None,\n",
       "       shuffle=True, tol=None, verbose=0, warm_start=False))]),\n",
       "       fit_params=None, iid=True, n_jobs=2,\n",
       "       param_grid=[{'clf': [SGDClassifier(alpha=0.001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.4, learning_rate='optimal',\n",
       "       loss='log', max_iter=500, n_iter=None, n_jobs=1,\n",
       "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True...r='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)], 'clf__C': [0.2, 0.4, 0.6, 0.8]}],\n",
       "       pre_dispatch='2*n_jobs', refit='log', return_train_score=True,\n",
       "       scoring={'auc': make_scorer(proba_scorer, needs_proba=True, func=<function roc_auc_score at 0x10816d6a8>), 'log': make_scorer(proba_scorer, greater_is_better=False, needs_proba=True, func=<function log_loss at 0x1080c8598>)},\n",
       "       verbose=5)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>mean_test_auc</th>\n",
       "      <th>mean_test_log</th>\n",
       "      <th>mean_train_auc</th>\n",
       "      <th>mean_train_log</th>\n",
       "      <th>param_clf</th>\n",
       "      <th>param_clf__C</th>\n",
       "      <th>param_clf__alpha</th>\n",
       "      <th>param_clf__l1_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>split5_test_auc</th>\n",
       "      <th>split5_test_log</th>\n",
       "      <th>split5_train_auc</th>\n",
       "      <th>split5_train_log</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>std_test_auc</th>\n",
       "      <th>std_test_log</th>\n",
       "      <th>std_train_auc</th>\n",
       "      <th>std_train_log</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.722055</td>\n",
       "      <td>0.010922</td>\n",
       "      <td>0.614400</td>\n",
       "      <td>-0.514005</td>\n",
       "      <td>0.616287</td>\n",
       "      <td>-0.511555</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593126</td>\n",
       "      <td>-0.516942</td>\n",
       "      <td>0.620537</td>\n",
       "      <td>-0.510772</td>\n",
       "      <td>0.085410</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.019804</td>\n",
       "      <td>0.006393</td>\n",
       "      <td>0.004584</td>\n",
       "      <td>0.001210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.681118</td>\n",
       "      <td>0.009633</td>\n",
       "      <td>0.615305</td>\n",
       "      <td>-0.514566</td>\n",
       "      <td>0.616365</td>\n",
       "      <td>-0.511647</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.593698</td>\n",
       "      <td>-0.516686</td>\n",
       "      <td>0.620203</td>\n",
       "      <td>-0.510888</td>\n",
       "      <td>0.076046</td>\n",
       "      <td>0.000368</td>\n",
       "      <td>0.019420</td>\n",
       "      <td>0.007558</td>\n",
       "      <td>0.004287</td>\n",
       "      <td>0.001130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.496573</td>\n",
       "      <td>0.009712</td>\n",
       "      <td>0.614601</td>\n",
       "      <td>-0.514096</td>\n",
       "      <td>0.616101</td>\n",
       "      <td>-0.511693</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.596252</td>\n",
       "      <td>-0.516009</td>\n",
       "      <td>0.619866</td>\n",
       "      <td>-0.510894</td>\n",
       "      <td>0.101484</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>0.019813</td>\n",
       "      <td>0.007305</td>\n",
       "      <td>0.004514</td>\n",
       "      <td>0.001255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.368736</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.615518</td>\n",
       "      <td>-0.513442</td>\n",
       "      <td>0.616801</td>\n",
       "      <td>-0.511398</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594747</td>\n",
       "      <td>-0.516407</td>\n",
       "      <td>0.620554</td>\n",
       "      <td>-0.510707</td>\n",
       "      <td>0.072741</td>\n",
       "      <td>0.000449</td>\n",
       "      <td>0.019710</td>\n",
       "      <td>0.006128</td>\n",
       "      <td>0.004400</td>\n",
       "      <td>0.001198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.309065</td>\n",
       "      <td>0.009658</td>\n",
       "      <td>0.615469</td>\n",
       "      <td>-0.513455</td>\n",
       "      <td>0.616800</td>\n",
       "      <td>-0.511400</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594727</td>\n",
       "      <td>-0.516420</td>\n",
       "      <td>0.620590</td>\n",
       "      <td>-0.510707</td>\n",
       "      <td>0.037185</td>\n",
       "      <td>0.000856</td>\n",
       "      <td>0.019685</td>\n",
       "      <td>0.006091</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>0.001198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4.310617</td>\n",
       "      <td>0.009160</td>\n",
       "      <td>0.615411</td>\n",
       "      <td>-0.513427</td>\n",
       "      <td>0.616794</td>\n",
       "      <td>-0.511408</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594802</td>\n",
       "      <td>-0.516371</td>\n",
       "      <td>0.620575</td>\n",
       "      <td>-0.510715</td>\n",
       "      <td>0.018626</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.019574</td>\n",
       "      <td>0.005931</td>\n",
       "      <td>0.004412</td>\n",
       "      <td>0.001199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.448951</td>\n",
       "      <td>0.009136</td>\n",
       "      <td>0.610784</td>\n",
       "      <td>-0.516399</td>\n",
       "      <td>0.609652</td>\n",
       "      <td>-0.515593</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584956</td>\n",
       "      <td>-0.519203</td>\n",
       "      <td>0.613509</td>\n",
       "      <td>-0.514872</td>\n",
       "      <td>0.027896</td>\n",
       "      <td>0.000510</td>\n",
       "      <td>0.021393</td>\n",
       "      <td>0.002647</td>\n",
       "      <td>0.004711</td>\n",
       "      <td>0.001022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.640309</td>\n",
       "      <td>0.009161</td>\n",
       "      <td>0.605521</td>\n",
       "      <td>-0.519150</td>\n",
       "      <td>0.603721</td>\n",
       "      <td>-0.518836</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.584295</td>\n",
       "      <td>-0.520903</td>\n",
       "      <td>0.608134</td>\n",
       "      <td>-0.518198</td>\n",
       "      <td>0.011166</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.020367</td>\n",
       "      <td>0.001587</td>\n",
       "      <td>0.004166</td>\n",
       "      <td>0.000759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.707424</td>\n",
       "      <td>0.009072</td>\n",
       "      <td>0.569861</td>\n",
       "      <td>-0.525305</td>\n",
       "      <td>0.562437</td>\n",
       "      <td>-0.525229</td>\n",
       "      <td>SGDClassifier(alpha=0.001, average=False, clas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.4</td>\n",
       "      <td>...</td>\n",
       "      <td>0.559313</td>\n",
       "      <td>-0.525537</td>\n",
       "      <td>0.577145</td>\n",
       "      <td>-0.525187</td>\n",
       "      <td>0.027801</td>\n",
       "      <td>0.000474</td>\n",
       "      <td>0.039232</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.028219</td>\n",
       "      <td>0.000836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.162854</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.615476</td>\n",
       "      <td>-0.513485</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>-0.511396</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594890</td>\n",
       "      <td>-0.516377</td>\n",
       "      <td>0.620586</td>\n",
       "      <td>-0.510705</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>0.000479</td>\n",
       "      <td>0.019629</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>0.001198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.164617</td>\n",
       "      <td>0.010577</td>\n",
       "      <td>0.615471</td>\n",
       "      <td>-0.513486</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>-0.511396</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594891</td>\n",
       "      <td>-0.516390</td>\n",
       "      <td>0.620586</td>\n",
       "      <td>-0.510704</td>\n",
       "      <td>0.011998</td>\n",
       "      <td>0.000627</td>\n",
       "      <td>0.019623</td>\n",
       "      <td>0.006206</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>0.001198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.155293</td>\n",
       "      <td>0.011075</td>\n",
       "      <td>0.615468</td>\n",
       "      <td>-0.513487</td>\n",
       "      <td>0.616822</td>\n",
       "      <td>-0.511396</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594892</td>\n",
       "      <td>-0.516394</td>\n",
       "      <td>0.620586</td>\n",
       "      <td>-0.510704</td>\n",
       "      <td>0.008770</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.019621</td>\n",
       "      <td>0.006205</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>0.001198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.159059</td>\n",
       "      <td>0.010679</td>\n",
       "      <td>0.615468</td>\n",
       "      <td>-0.513487</td>\n",
       "      <td>0.616823</td>\n",
       "      <td>-0.511396</td>\n",
       "      <td>LogisticRegression(C=1.0, class_weight=None, d...</td>\n",
       "      <td>0.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.594892</td>\n",
       "      <td>-0.516396</td>\n",
       "      <td>0.620586</td>\n",
       "      <td>-0.510704</td>\n",
       "      <td>0.005122</td>\n",
       "      <td>0.000441</td>\n",
       "      <td>0.019621</td>\n",
       "      <td>0.006205</td>\n",
       "      <td>0.004407</td>\n",
       "      <td>0.001198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13 rows  43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  mean_score_time  mean_test_auc  mean_test_log  \\\n",
       "0        4.722055         0.010922       0.614400      -0.514005   \n",
       "1        4.681118         0.009633       0.615305      -0.514566   \n",
       "2        4.496573         0.009712       0.614601      -0.514096   \n",
       "3        4.368736         0.009014       0.615518      -0.513442   \n",
       "4        4.309065         0.009658       0.615469      -0.513455   \n",
       "5        4.310617         0.009160       0.615411      -0.513427   \n",
       "6        4.448951         0.009136       0.610784      -0.516399   \n",
       "7        4.640309         0.009161       0.605521      -0.519150   \n",
       "8        4.707424         0.009072       0.569861      -0.525305   \n",
       "9        0.162854         0.010790       0.615476      -0.513485   \n",
       "10       0.164617         0.010577       0.615471      -0.513486   \n",
       "11       0.155293         0.011075       0.615468      -0.513487   \n",
       "12       0.159059         0.010679       0.615468      -0.513487   \n",
       "\n",
       "    mean_train_auc  mean_train_log  \\\n",
       "0         0.616287       -0.511555   \n",
       "1         0.616365       -0.511647   \n",
       "2         0.616101       -0.511693   \n",
       "3         0.616801       -0.511398   \n",
       "4         0.616800       -0.511400   \n",
       "5         0.616794       -0.511408   \n",
       "6         0.609652       -0.515593   \n",
       "7         0.603721       -0.518836   \n",
       "8         0.562437       -0.525229   \n",
       "9         0.616822       -0.511396   \n",
       "10        0.616822       -0.511396   \n",
       "11        0.616822       -0.511396   \n",
       "12        0.616823       -0.511396   \n",
       "\n",
       "                                            param_clf param_clf__C  \\\n",
       "0   SGDClassifier(alpha=0.001, average=False, clas...          NaN   \n",
       "1   SGDClassifier(alpha=0.001, average=False, clas...          NaN   \n",
       "2   SGDClassifier(alpha=0.001, average=False, clas...          NaN   \n",
       "3   SGDClassifier(alpha=0.001, average=False, clas...          NaN   \n",
       "4   SGDClassifier(alpha=0.001, average=False, clas...          NaN   \n",
       "5   SGDClassifier(alpha=0.001, average=False, clas...          NaN   \n",
       "6   SGDClassifier(alpha=0.001, average=False, clas...          NaN   \n",
       "7   SGDClassifier(alpha=0.001, average=False, clas...          NaN   \n",
       "8   SGDClassifier(alpha=0.001, average=False, clas...          NaN   \n",
       "9   LogisticRegression(C=1.0, class_weight=None, d...          0.2   \n",
       "10  LogisticRegression(C=1.0, class_weight=None, d...          0.4   \n",
       "11  LogisticRegression(C=1.0, class_weight=None, d...          0.6   \n",
       "12  LogisticRegression(C=1.0, class_weight=None, d...          0.8   \n",
       "\n",
       "   param_clf__alpha param_clf__l1_ratio      ...       split5_test_auc  \\\n",
       "0            0.0001                 0.1      ...              0.593126   \n",
       "1            0.0001                 0.2      ...              0.593698   \n",
       "2            0.0001                 0.4      ...              0.596252   \n",
       "3             0.001                 0.1      ...              0.594747   \n",
       "4             0.001                 0.2      ...              0.594727   \n",
       "5             0.001                 0.4      ...              0.594802   \n",
       "6               0.1                 0.1      ...              0.584956   \n",
       "7               0.1                 0.2      ...              0.584295   \n",
       "8               0.1                 0.4      ...              0.559313   \n",
       "9               NaN                 NaN      ...              0.594890   \n",
       "10              NaN                 NaN      ...              0.594891   \n",
       "11              NaN                 NaN      ...              0.594892   \n",
       "12              NaN                 NaN      ...              0.594892   \n",
       "\n",
       "    split5_test_log  split5_train_auc  split5_train_log  std_fit_time  \\\n",
       "0         -0.516942          0.620537         -0.510772      0.085410   \n",
       "1         -0.516686          0.620203         -0.510888      0.076046   \n",
       "2         -0.516009          0.619866         -0.510894      0.101484   \n",
       "3         -0.516407          0.620554         -0.510707      0.072741   \n",
       "4         -0.516420          0.620590         -0.510707      0.037185   \n",
       "5         -0.516371          0.620575         -0.510715      0.018626   \n",
       "6         -0.519203          0.613509         -0.514872      0.027896   \n",
       "7         -0.520903          0.608134         -0.518198      0.011166   \n",
       "8         -0.525537          0.577145         -0.525187      0.027801   \n",
       "9         -0.516377          0.620586         -0.510705      0.005832   \n",
       "10        -0.516390          0.620586         -0.510704      0.011998   \n",
       "11        -0.516394          0.620586         -0.510704      0.008770   \n",
       "12        -0.516396          0.620586         -0.510704      0.005122   \n",
       "\n",
       "    std_score_time  std_test_auc  std_test_log  std_train_auc  std_train_log  \n",
       "0         0.002446      0.019804      0.006393       0.004584       0.001210  \n",
       "1         0.000368      0.019420      0.007558       0.004287       0.001130  \n",
       "2         0.000686      0.019813      0.007305       0.004514       0.001255  \n",
       "3         0.000449      0.019710      0.006128       0.004400       0.001198  \n",
       "4         0.000856      0.019685      0.006091       0.004412       0.001198  \n",
       "5         0.000262      0.019574      0.005931       0.004412       0.001199  \n",
       "6         0.000510      0.021393      0.002647       0.004711       0.001022  \n",
       "7         0.000646      0.020367      0.001587       0.004166       0.000759  \n",
       "8         0.000474      0.039232      0.000648       0.028219       0.000836  \n",
       "9         0.000479      0.019629      0.006209       0.004407       0.001198  \n",
       "10        0.000627      0.019623      0.006206       0.004407       0.001198  \n",
       "11        0.000676      0.019621      0.006205       0.004407       0.001198  \n",
       "12        0.000441      0.019621      0.006205       0.004407       0.001198  \n",
       "\n",
       "[13 rows x 43 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_df = pd.DataFrame(grid.cv_results_)\n",
    "cv_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmml_pipe = make_pmml_pipeline(grid, X.columns.values, y.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn2pmml(pmml_pipe, 'pmml_model.pmml', with_repr=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
